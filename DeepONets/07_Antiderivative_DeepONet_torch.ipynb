{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operator Learning with DeepXDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as  dt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N$: Number of functions $u(x)$ in training dataset  \n",
    "$P$: Number fo points inside domain at which $G(u)$ is evaluated (output evaluations)  \n",
    "$m$: Number of points at which input function is evaluated  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/antiderivative_unaligned_train.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m d \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mdataset/antiderivative_unaligned_train.npz\u001b[39;49m\u001b[39m\"\u001b[39;49m, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      3\u001b[0m X_train \u001b[39m=\u001b[39m (d[\u001b[39m\"\u001b[39m\u001b[39mX_train0\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32), d[\u001b[39m\"\u001b[39m\u001b[39mX_train1\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32))\n\u001b[0;32m      4\u001b[0m y_train \u001b[39m=\u001b[39m d[\u001b[39m\"\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\1833097\\Miniconda3\\envs\\jax_env\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/antiderivative_unaligned_train.npz'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "d = np.load(\"dataset/antiderivative_unaligned_train.npz\", allow_pickle=True)\n",
    "X_train = (d[\"X_train0\"].astype(np.float32), d[\"X_train1\"].astype(np.float32))\n",
    "y_train = d[\"y_train\"].astype(np.float32)\n",
    "d = np.load(\"dataset/antiderivative_unaligned_test.npz\", allow_pickle=True)\n",
    "X_test = (d[\"X_test0\"].astype(np.float32), d[\"X_test1\"].astype(np.float32))\n",
    "y_test = d[\"y_test\"].astype(np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "Effective data generation requires parallel data generation when training.  \n",
    "__ID__:  Python string that identifies sample of sample\n",
    "__train__: Trining data\n",
    "__validation__: Validation data points  \n",
    "\n",
    "We will access training and validation samples using `ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.from_numpy(X_train[0])\n",
    "x  = torch.from_numpy(X_train[1])\n",
    "v = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u.shape)#(Number of u Funcs sensor resolution) (150,100)\n",
    "print(x.shape)#(Number of u funcs,input dimesniom) (100,1)\n",
    "print(v.shape)# (dataset size, output sensors )(150,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.has_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(dt.Dataset):\n",
    "    \n",
    "    def __init__(self,inputs:torch.Tensor,location:torch.Tensor,outputs:torch.Tensor):\n",
    "        self.input_signals = inputs\n",
    "        self.collocation_points = location\n",
    "        self.output_signals = outputs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_signals)\n",
    "    \n",
    "    def __getitem__(self, index) -> tuple:\n",
    "        v = self.input_signals[index,:]\n",
    "        x = self.collocation_points[index,:]\n",
    "        u = self.output_signals[index,:]\n",
    "        return ((v,x),u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = DataGenerator(u,x,v)\n",
    "training_loader = dt.DataLoader(training_set,batch_size = 32,\n",
    "                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ((b_in,y_loc),d_out) in training_loader:\n",
    "    print(b_in.shape)\n",
    "    print(y_loc.shape)\n",
    "    print(d_out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    \"\"\"Base class for neural network modules\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.regulariser = None\n",
    "    @property\n",
    "    def num_trainable_parameters(self):\n",
    "        \"\"\"Evaluate number of trainable parameters for NN\"\"\"\n",
    "        return sum(v.numel() for v in self.parameters() if v.requires_grad)\n",
    "#%%\n",
    "class MLP(NN):\n",
    "    \"\"\"Mulilayer perceptron network fully connected\"\"\"\n",
    "    def __init__(self,layer_sizes,\n",
    "                 activation = nn.ReLU(),\n",
    "                 kernel_initialiser=nn.init.xavier_normal_,\n",
    "                 zero_init=nn.init.zeros_):\n",
    "        super().__init__()\n",
    "        self.activation = activation       \n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(l_in,l_out,dtype = torch.float32) \n",
    "                for (l_in,l_out) in zip(layer_sizes,layer_sizes[1:])])\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self,module:nn.Linear,initialiser = nn.init.xavier_normal_,\n",
    "                      zero_initialiser = nn.init.zeros_):\n",
    "        if isinstance(module,nn.Linear):\n",
    "            initialiser(module.weight)\n",
    "            zero_initialiser(module.bias)   \n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.layers[-1](x)\n",
    "        \n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONet(NN):\n",
    "    \"\"\"Deep operator network for dataset in the format of Cartesian product.\n",
    "\n",
    "    Args:\n",
    "        layer_sizes_branch: A list of integers as the width of a fully connected network,\n",
    "            or `(dim, f)` where `dim` is the input dimension and `f` is a network\n",
    "            function. The width of the last layer in the branch and trunk net should be\n",
    "            equal.\n",
    "        layer_sizes_trunk (list): A list of integers as the width of a fully connected\n",
    "            network.\n",
    "        activation: If `activation` is a ``string``, then the same activation is used in\n",
    "            both trunk and branch nets. If `activation` is a ``dict``, then the trunk\n",
    "            net uses the activation `activation[\"trunk\"]`, and the branch net uses\n",
    "            `activation[\"branch\"]`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_sizes_branch:list,\n",
    "        layer_sizes_trunk:list,\n",
    "        *args,**kwargs):\n",
    "        super().__init__()\n",
    "        #activation_branch = activation_trunk = activation\n",
    "\n",
    "        self.branch = MLP(layer_sizes_branch, *args,**kwargs)\n",
    "        self.trunk = MLP(layer_sizes_trunk, *args,**kwargs)\n",
    "        self.b = torch.tensor(0.0,requires_grad = True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        v_func:torch.Tensor = inputs[0] # Input signal (batch_size,resolution)\n",
    "        y_loc:torch.Tensor = inputs[1].swapaxes(2,1) # Collocation points (batch_size,input_dim,num_points)->(b,p,n)\n",
    "        # Branch net to encode the input function\n",
    "        v_func = self.branch(v_func)\n",
    "        # Trunk net to encode the domain of the output function\n",
    "        y_loc = self.trunk(y_loc).swapaxes(2,1) #Output dim (batch_size,output_layer_dim,)\n",
    "        # Dot product\n",
    "        if v_func.shape[-1] != y_loc.shape[1]:\n",
    "            raise AssertionError(\n",
    "                \"Output sizes of branch net and trunk net do not match.\")\n",
    "        x = torch.einsum(\"bl,blp->bp\", v_func, y_loc)\n",
    "        # Add bias\n",
    "        x += self.b\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a network\n",
    "m = 100\n",
    "dim_x = 1\n",
    "net = DeepONet(\n",
    "    [m, 40, 40],\n",
    "    [dim_x, 40, 40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "niter = 10000\n",
    "opt = optim.Adam(net.parameters(),lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2000 % 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "Batch :49 \t Loss\t0.07952\n",
      "Batch :99 \t Loss\t0.09278\n",
      "Batch :149 \t Loss\t0.09814\n",
      "Batch :199 \t Loss\t0.07178\n",
      "Batch :249 \t Loss\t0.08550\n",
      "Batch :299 \t Loss\t0.07971\n",
      "EPOCH 1\n",
      "Batch :49 \t Loss\t0.08447\n",
      "Batch :99 \t Loss\t0.08626\n",
      "Batch :149 \t Loss\t0.08590\n",
      "Batch :199 \t Loss\t0.08889\n",
      "Batch :249 \t Loss\t0.08770\n",
      "Batch :299 \t Loss\t0.07737\n",
      "EPOCH 2\n",
      "Batch :49 \t Loss\t0.08509\n",
      "Batch :99 \t Loss\t0.09161\n",
      "Batch :149 \t Loss\t0.08258\n",
      "Batch :199 \t Loss\t0.07760\n",
      "Batch :249 \t Loss\t0.08983\n",
      "Batch :299 \t Loss\t0.08378\n",
      "EPOCH 3\n",
      "Batch :49 \t Loss\t0.07894\n",
      "Batch :99 \t Loss\t0.08370\n",
      "Batch :149 \t Loss\t0.07284\n",
      "Batch :199 \t Loss\t0.09026\n",
      "Batch :249 \t Loss\t0.09832\n",
      "Batch :299 \t Loss\t0.08609\n",
      "EPOCH 4\n",
      "Batch :49 \t Loss\t0.09658\n",
      "Batch :99 \t Loss\t0.08765\n",
      "Batch :149 \t Loss\t0.07638\n",
      "Batch :199 \t Loss\t0.08724\n",
      "Batch :249 \t Loss\t0.07935\n",
      "Batch :299 \t Loss\t0.08022\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(f'EPOCH {epoch}')\n",
    "    \n",
    "    net.train(True)\n",
    "    \n",
    "    running_loss = 0.\n",
    "    last_loss = 0. \n",
    "    \n",
    "    for i,data in enumerate(training_loader):\n",
    "        ((u,y),labels) = data\n",
    "        output = net((u,y[:,None,:]))\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%50 ==49:\n",
    "            last_loss = running_loss/32\n",
    "            print(f'Batch :{i} \\t Loss\\t{last_loss:.5f}')\n",
    "            running_loss = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a Model\n",
    "model = dde.Model(data, net)\n",
    "\n",
    "# Compile and Train\n",
    "model.compile(\"adam\", lr=0.001, metrics=[\"mean l2 relative error\"])\n",
    "losshistory, train_state = model.train(iterations=10000)\n",
    "\n",
    "# Plot the loss trajectory\n",
    "dde.utils.plot_loss_history(losshistory)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
